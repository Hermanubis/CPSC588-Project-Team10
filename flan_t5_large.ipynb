{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc97ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/ying_rex/hc838/conda_envs/quad_env/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/gpfs/gibbs/project/ying_rex/hc838/conda_envs/quad_env/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/ying_rex/hc838/conda_envs/quad_env/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from peft import IA3Config, TaskType\n",
    "from peft import get_peft_model\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeLsum\"], use_stemmer=True)\n",
    "\n",
    "device = f\"gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d5dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = sys.argv[2]\n",
    "model_name_or_path = \"google/flan-t5-large\"\n",
    "tokenizer_name_or_path = \"google/flan-t5-large\"\n",
    "\n",
    "text_column = \"document\"\n",
    "label_column = \"summary\"\n",
    "max_src_length = 512\n",
    "max_tgt_length = 256\n",
    "\n",
    "# experiment hyperparameters\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# loading model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "\n",
    "# loading dataset\n",
    "\n",
    "\n",
    "# data preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_src_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=max_tgt_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69da683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d9d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "folder_path = \"./Confidential_Data\"\n",
    "file_name = \"200_Cases_Cleaned_Data.xlsx\"\n",
    "file_path = os.path.join(folder_path,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12a9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.read_excel(file_path, index_col=0,sheet_name='Original').replace(np.nan, '')\n",
    "data_cleaned = pd.read_excel(file_path, index_col=0,sheet_name='Cleaned').replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e838be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    previous_report_data = []\n",
    "    MRI_finding = []\n",
    "    MRI_History = \"\"\n",
    "    Indication = \"\"\n",
    "    Impression = \"\"\n",
    "    for i in example[0].split(\"\\n\"):\n",
    "        if \"COMPARISON\" in i:\n",
    "            pass\n",
    "        elif \"MRI BRAIN\" in i:\n",
    "            pass\n",
    "        elif \"TECHNIQUE\" in i:\n",
    "            pass\n",
    "        elif \"History\" in i:\n",
    "            MRI_History = i\n",
    "        elif \"INDICATION\" in i:\n",
    "            Indication = i\n",
    "        elif \"Impression\" in i:\n",
    "            Impression = i\n",
    "        else:\n",
    "            MRI_finding.append(i)\n",
    "\n",
    "    for col_id in range(1,21):\n",
    "        extracted_data = example[col_id]\n",
    "        if extracted_data != None:\n",
    "            for sentence in extracted_data.split(\"\\n,.\"):\n",
    "                if \"Reported By:\" in sentence:\n",
    "                    pass\n",
    "                elif \"Report Initiated By:\" in sentence:\n",
    "                    pass\n",
    "                elif \"Discussed with\"in sentence:\n",
    "                    pass\n",
    "                elif sentence == \"\":\n",
    "                    pass \n",
    "                elif \"TECHNIQUE\" in sentence:\n",
    "                    pass\n",
    "                else:\n",
    "                    previous_report_data.append(sentence + \"\\n\")\n",
    "    return Indication,Impression,\"\".join(MRI_finding),MRI_History+\"\".join(previous_report_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e97b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id  = 5\n",
    "example = data_cleaned.iloc[patient_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "127d736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indication,Impression,MRI_finding,MRI_History = preprocess_function(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34d88d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Persistent AMS with frontotemporal slowing on EEG; evaluate for lesion.FINDINGS:Some sequences are degraded by motion artifacts.There are foci of high T2/FLAIR signal in the subcortical and periventricular white matter, nonspecific but most likely due to chronic microvascular ischemic change..Redemonstration of diffuse parenchymal volume loss.There is no intracranial hemorrhage or major vascular distribution infarct.No abnormal enhancement is seen.There is no mass effect, edema, or midline shift.No acute hydrocephalus.  No extra-axial collection is seen.The paranasal sinuses are clear. Minimal fluid signal in the mastoid air cells.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRI_finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b2cf635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INDICATION: Altered mental status, nontraumatic (Ped 0-18y)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f0c61a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e87fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Assess stool burden/constipation.\n",
      "\n",
      "\n",
      "\n",
      "Mild colonic stool burden.\n",
      "\n",
      "\n",
      " Aphasia. 86 y.o. female w/ hx of progressive dementia, HTN, HLD, hypothyroidism who is sent to the ER as a stroke alert. Last seen normal yesterday at 9 PM. She normally wakes up at 4 PM but she didn't leave her room so family went to check on her and found her not following commands and not speaking. On arrival pt has no clear neuro deficits, though exam very difficult 2/2 pt's inability to follow commands well. \n",
      "\n",
      "\n",
      " Neuro deficit, acute, stroke suspected. \n",
      "\n",
      " Neuro deficit, acute, stroke suspected. Altered mental status. Aphasia.\n",
      "\n",
      " 83 years of age Female, memory changes, gait \n",
      "\n",
      "IMPRESSION: \n",
      "1. No laryngeal penetration or aspiration. \n",
      "2. Final feeding recommendations will be reported separately by speech pathology.\n",
      "\n",
      "\n",
      " Failed 3oz swallow. Concern for aspiration.\n",
      "\n",
      "IMPRESSION: \n",
      "1. Aspiration of thin liquids. Laryngeal penetration with nectar and honey consistency thick liquids.\n",
      "2. Final feeding recommendations will be reported separately by speech pathology.\n",
      "\n",
      "\n",
      "  Confirm OG placement\n",
      "\n",
      "Impression:\n",
      "\n",
      "1. Interval repositioning of the OG tube with tip and sidehole in the region of the stomach, with the tip now pointing distally.\n",
      "2. Improving pulmonary edema.\n",
      "\n",
      "\n",
      " f/u pulmonary edema\n",
      "\n",
      "IMPRESSION: \n",
      "Improving pulmonary edema.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MRI_History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469e3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "606b9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"Nov14.txt\"\n",
    "output_file = open(output_filename ,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2c1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patient_id  = 20\n",
    "example = data_cleaned.iloc[patient_id]\n",
    "prompt1 = \"Give me the age, gender and medical history of this patient for in one sentence given:\"\n",
    "prompt2 = \"Tell me what does the petient present with given:\"\n",
    "prompt3 = \"Medical Vignette: \"\n",
    "Indication,Impression,MRI_finding,MRI_History = preprocess_function(example)\n",
    "model_inputs = tokenizer(\n",
    "    [prompt1 +MRI_History,prompt2 +MRI_History],\n",
    "    max_length=max_src_length,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c45e49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "One_shot = prompt1 + \"\"\"\n",
    "\n",
    "Impression: No demonstrable flow within the dorsalis pedis artery bilaterally suggesting occlusion.\n",
    "\n",
    "Dampened distal arterial waveforms in the calf arteries bilaterally, as described above, consistent with severe stenosis at the level of the calf bilaterally. Similarly, very slow flow in the right distal posterior tibial artery and left mid posterior tibial artery are consistent with high-grade stenoses proximally. The distal left posterior tibial artery is not visualized, possibly occluded. See details above. \n",
    "\n",
    "INDICATION: Sepsis from VRC UTI with multisystem organ failure. Concern for cerebral hemorrhage\n",
    "\n",
    "IMPRESSION: Compared to 18 hours prior, focal parenchymal hypodensities right parietal and left occipital regions appear similar. Adjacent hyperdensities are less conspicuous but are suspicious for subarachnoid blood. Further evaluation with brain MRI would be useful, as clinically appropriate.\n",
    "\n",
    "No hydrocephalus or herniation\n",
    "\n",
    "Clinical History: Acute liver injury, evaluate for hepatic thrombosis\n",
    "\n",
    "Impression: Normal directionality and flow of the portal veins, hepatic veins and hepatic arteries. No occlusive portal venous thrombus, evaluation for nonocclusive thrombus is limited.\n",
    "\n",
    "Incidental note of bilateral pleural effusions.\n",
    "\n",
    "\"\"\" + prompt3 +\"\"\"\n",
    "\n",
    "78F with history of acute liver failure, DIC, Sepsis, multi-organ failure,and  peripheral arterial disease who presents with acute neuro deficits and volume overload. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dac271ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_src_length = 900\n",
    "model_inputs = tokenizer(\n",
    "    [One_shot + prompt1 +MRI_History + prompt3],\n",
    "    max_length=max_src_length,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e31d85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R/o IPH. Additional clinical information: 58-year-old female with prior history of GBM in the right parietal lobe with left-sided weakness status post resection, radiation, and chemotherapy. on anticoagulation, PTT now therapeutic x2, evaluate for bleed. change in neuro exam c/f bleed. Neuro deficit, acute, stroke suspected. Prior GBM, new PE, eval for AC safety. Neuro deficit, acute, stroke suspected Concern for possible hyperdensity.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            max_new_tokens=300,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            length_penalty=9.0,\n",
    "        )\n",
    "outcome = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)\n",
    "outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8da684c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_src_length = 900\n",
    "for patient_id in range(200):\n",
    "    output_file = open(output_filename,\"a\")\n",
    "    example = data_cleaned.iloc[patient_id]\n",
    "    prompt1 = \"Give me the age, gender and medical history of this patient for in one sentence given:\"\n",
    "    prompt2 = \"Tell me what does the petient present with given:\"\n",
    "    prompt3 = \"Medical Vignette: \"\n",
    "    Indication,Impression,MRI_finding,MRI_History = preprocess_function(example)\n",
    "    model_inputs = tokenizer(\n",
    "        [One_shot + prompt1 +MRI_History + prompt3],\n",
    "        max_length=max_src_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            max_new_tokens=300,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            length_penalty=9.0,\n",
    "        )\n",
    "    outcome = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)\n",
    "    clinical_vignette = \"patient_id\" + str(patient_id)+\"###\" + outcome[0]+\"\\n\"\n",
    "    output_file.write(clinical_vignette)\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbe344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96848c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
